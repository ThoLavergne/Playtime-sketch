{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cet avion peut voler pendant  52438  s, soit  873  min, soit 2039  km à une vitesse moyenne de  140  km/h et sa vitesse max sera de  200  km/h\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from gymenv.PlaytimeEnv import PlaytimeEnv\n",
    "from objects.Maneuver import Mission_Maneuver\n",
    "from objects.Plane import ULM\n",
    "from function.tools import *\n",
    "from function.j_methods import * \n",
    "\n",
    "env = gym.make('MountainCar-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The observation space: Box(2,)\n",
      "The action space: Discrete(3)\n"
     ]
    }
   ],
   "source": [
    "# Observation and action space \n",
    "obs_space = env.observation_space\n",
    "action_space = env.action_space\n",
    "print(\"The observation space: {}\".format(obs_space))\n",
    "print(\"The action space: {}\".format(action_space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MountainCarContinuous-v0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "def policy(observation):\n",
    "    position, velocity = observation\n",
    "    ret = []\n",
    "    if velocity < 0:\n",
    "        ret.append(-0.75)\n",
    "    elif velocity > 0:\n",
    "        ret.append(0.75)\n",
    "    else:\n",
    "        ret.append(1)\n",
    "    return ret\n",
    "\n",
    "num_steps = 150\n",
    "obs = env.reset()\n",
    "for step in range(num_steps):\n",
    "    # take random action, but you can also do something more intelligent\n",
    "    # action = my_intelligent_agent_fn(obs) \n",
    "    action = policy(obs)\n",
    "    # action = env.action_space.sample()\n",
    "    # apply the action\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    # Render the env\n",
    "    env.render()\n",
    "\n",
    "    # Wait a bit before the next frame unless you want to see a crazy fast video\n",
    "    time.sleep(0.0005)\n",
    "    \n",
    "    # If the epsiode is up, then start another one\n",
    "    if done:\n",
    "        \n",
    "        env.reset()\n",
    "\n",
    "# Close the env\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Plane': ULM, 'GoalDistance': 0, 'RtBDistance': 0, 'Fuel': 3, 'Meteo': 'Sunny', 'MissionType': SCAR, 'Strength': 'Weak', 'TimeMin': 300}\n"
     ]
    }
   ],
   "source": [
    "param_list = {\n",
    "    'Plane': [ULM],\n",
    "    'GoalDistance': [0, 10, 15, 20, 30],\n",
    "    'RtBDistance': [0, 10, 15, 20, 30],\n",
    "    'Fuel': [1, 2, 3, 3, 4, 10],\n",
    "    # Start with just 2 states : good (sunny, no clouds) and bad (cloudy or rainy)\n",
    "    'Meteo': [\"Sunny\", \"Cloudy\", \"Misty\"],\n",
    "    'MissionType': [Mission_Maneuver.SCAR],  # , Mission_Maneuver.CAS\n",
    "    # Add ennemies number afterwards, weaponry\n",
    "    'Strength': ['Weak', 'Equal', 'Strong'],\n",
    "    'TimeMin': [0, 300],\n",
    "}\n",
    "combinations = get_all_combinations(param_list)\n",
    "first_c = list(filter(lambda c : c['TimeMin'] == 300 and c['Fuel'] == 3, combinations))[0]\n",
    "print(first_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters : c0 :  3\n",
      "c1 :  300\n",
      "Min\n",
      "Target  [3.0, 392.27]\n",
      "Reset, new obs :  [  1.89 264.58]\n",
      "OrderedDict([('altitude', 34), ('distance', 2), ('speed', 9)]) ([1.77, 248.54], 0.005656495721709461, False, {})\n"
     ]
    }
   ],
   "source": [
    "env = PlaytimeEnv(first_c)\n",
    "env.reset()\n",
    "a = env.action_space.sample()\n",
    "print(a, env.step(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters : c0 :  3\n",
      "c1 :  300\n",
      "Min\n",
      "Target  [3.0, 392.27]\n",
      "Reset, new obs :  [  4.51 592.29]\n",
      "[4.45, 585.34] 0.003572047301050359 False {}\n",
      "[4.33, 571.89] 0.004185946438303754 False {}\n",
      "[4.33, 573.63] 0.0041457857258939135 False {}\n",
      "[4.21, 559.84] 0.004931946535726772 False {}\n",
      "[4.09, 547.03] 0.005928089898297691 False {}\n",
      "[3.97, 534.35] 0.007255967307513697 False {}\n",
      "[3.91, 528.58] 0.008061779025024564 False {}\n",
      "[3.85, 521.24] 0.009122048447199299 False {}\n",
      "[3.73, 507.09] 0.011930526160064712 False {}\n",
      "[3.61, 494.66] 0.016010784864684848 False {}\n",
      "[3.61, 494.66] 0.016010784864684848 False {}\n",
      "[3.61, 494.66] 0.016010784864684848 False {}\n",
      "[3.61, 495.25] 0.015919054790202777 False {}\n",
      "[3.55, 489.73] 0.018655672257149786 False {}\n",
      "[3.55, 489.73] 0.018655672257149786 False {}\n",
      "[0.43000000000000016, 85.36000000000001]\n",
      "[3.43, 477.63] 0.027244393103899207 True {}\n",
      "Reset now\n",
      "Reset, new obs :  [  2.36 329.44]\n",
      "[2.3, 322.52] 0.020481310803891442 False {}\n",
      "[2.31, 320.85] 0.020292290147281455 False {}\n",
      "[2.31, 320.85] 0.020292290147281455 False {}\n",
      "[2.36, 328.2] 0.0243873887935071 False {}\n",
      "[2.48, 342.89] 0.03894444963703773 False {}\n",
      "[2.6, 356.01] 0.06894649751792613 False {}\n",
      "[2.66, 362.97] 0.10038144950813108 False {}\n",
      "[2.72, 370.32] 0.16270745200130185 False {}\n",
      "[2.84, 383.9] 0.7467144563918746 False {}\n",
      "[2.84, 383.9] 0.7467144563918746 False {}\n",
      "[2.9, 389.82] 4.08163265306124 False {}\n",
      "[0.020000000000000018, 12.240000000000009]\n",
      "[3.02, 404.51] 4.084967320261431 True {}\n",
      "Reset now\n",
      "Reset, new obs :  [  1.77 257.26]\n",
      "[1.65, 244.38] 0.005008727708031244 False {}\n",
      "[1.71, 251.73] 0.005515823242134711 False {}\n",
      "[1.71, 251.27] 0.005497828357798671 False {}\n",
      "[1.71, 251.27] 0.005497828357798671 False {}\n",
      "[1.77, 257.71] 0.006041974807381843 False {}\n",
      "[1.89, 272.4] 0.007515649461090355 False {}\n",
      "[2.01, 286.21] 0.009523863945889213 False {}\n",
      "[2.01, 285.36] 0.009448143392582641 False {}\n",
      "[2.13, 298.81] 0.012298580005952514 False {}\n",
      "[2.13, 298.81] 0.012298580005952514 False {}\n",
      "[2.25, 312.7] 0.01675673411252147 False {}\n",
      "[2.31, 318.89] 0.01975027749139876 False {}\n",
      "[2.37, 324.76] 0.023512095797683128 False {}\n",
      "[2.43, 331.75] 0.028988532136686743 False {}\n",
      "[2.43, 331.75] 0.028988532136686743 False {}\n",
      "[2.49, 339.09] 0.03687070917122021 False {}\n",
      "[2.49, 338.05] 0.036163487896080634 False {}\n",
      "[2.61, 352.06] 0.06376778324055123 False {}\n",
      "[2.61, 351.73] 0.0632487065639508 False {}\n",
      "[2.61, 351.4] 0.0627380123342932 False {}\n",
      "[2.67, 357.47] 0.08707767328456993 False {}\n",
      "[2.67, 357.16] 0.08630883025642362 False {}\n",
      "[2.73, 364.2] 0.13194526910237636 False {}\n",
      "[2.79, 370.36] 0.21733933189889412 False {}\n",
      "[2.85, 376.85] 0.43233895373973336 False {}\n",
      "[2.91, 383.64] 1.2874983906270143 False {}\n",
      "[2.97, 390.18] 15.948963317384663 False {}\n",
      "[0.029999999999999805, 4.470000000000027]\n",
      "[3.03, 396.74] 7.457121551081285 True {}\n",
      "Reset now\n",
      "Reset, new obs :  [  4.39 578.82]\n",
      "[4.39, 580.53] 0.0038214408819274136 False {}\n",
      "[4.39, 580.97] 0.0038125302619589547 False {}\n",
      "[4.27, 567.65] 0.004489688532347758 False {}\n",
      "[4.15, 553.9] 0.005379974122324471 False {}\n",
      "[4.09, 546.55] 0.005946533527745338 False {}\n",
      "[4.03, 541.18] 0.006519869628686905 False {}\n",
      "[4.03, 542.21] 0.006475081942161974 False {}\n",
      "[4.03, 543.28] 0.006429201949591199 False {}\n",
      "[4.03, 544.38] 0.0063827084768113 False {}\n",
      "[3.97, 538.16] 0.0070664736106076246 False {}\n",
      "[3.97, 539.93] 0.006981767811536953 False {}\n",
      "[3.85, 527.1] 0.008725584723246263 False {}\n",
      "[3.85, 528.39] 0.00864289294912793 False {}\n",
      "[3.79, 523.07] 0.00967754422637711 False {}\n",
      "[3.73, 517.86] 0.010907421082081611 False {}\n",
      "[3.67, 512.76] 0.012387229757098812 False {}\n",
      "[3.67, 513.54] 0.01230755597784148 False {}\n",
      "[3.55, 502.11] 0.01655300271469245 False {}\n",
      "[3.55, 504.73] 0.016167364557903414 False {}\n",
      "[0.4900000000000002, 107.90000000000003]\n",
      "[3.49, 500.17] 0.018913960394166922 True {}\n",
      "Reset now\n",
      "Reset, new obs :  [  3.08 411.86]\n",
      "[2.96, 397.52] 4.761904761904757 False {}\n",
      "[0.020000000000000018, 11.560000000000002]\n",
      "[3.02, 403.83] 4.32525951557093 True {}\n",
      "Reset now\n",
      "Reset, new obs :  [  5.23 686.14]\n",
      "[5.11, 673.42] 0.0016856967785491715 False {}\n",
      "[5.11, 674.46] 0.0016794842102452227 False {}\n",
      "[5.05, 667.11] 0.0017748685709823187 False {}\n",
      "[4.93, 654.03] 0.001979426631364253 False {}\n",
      "[4.81, 641.02] 0.002221050001388157 False {}\n",
      "[4.69, 628.71] 0.002502605212025718 False {}\n",
      "[4.63, 621.36] 0.0026779734275408675 False {}\n",
      "[4.57, 614.01] 0.0028724753096384752 False {}\n",
      "[4.57, 616.56] 0.002839817536043674 False {}\n",
      "[4.51, 609.21] 0.003052695010736328 False {}\n",
      "[4.39, 595.18] 0.0035455347712367797 False {}\n",
      "[4.33, 587.83] 0.003844751990428104 False {}\n",
      "[4.33, 589.19] 0.003818198757099939 False {}\n",
      "[4.27, 583.98] 0.004107253532956808 False {}\n",
      "[4.15, 569.29] 0.004912242782687291 False {}\n",
      "[4.09, 561.94] 0.005407150307423529 False {}\n",
      "[4.09, 564.19] 0.005336384322129771 False {}\n",
      "[4.09, 564.19] 0.005336384322129771 False {}\n",
      "[3.97, 552.7] 0.006426029016091415 False {}\n",
      "[3.91, 548.82] 0.007019489612910241 False {}\n",
      "[3.85, 543.31] 0.00778913260219342 False {}\n",
      "[3.79, 539.87] 0.008576035127439879 False {}\n",
      "[3.79, 540.9] 0.008516603544440064 False {}\n",
      "[3.67, 530.55] 0.01079358774539222 False {}\n",
      "[3.55, 515.86] 0.014711399127614034 False {}\n",
      "[3.55, 517.01] 0.014575772151529732 False {}\n",
      "[0.4900000000000002, 122.25999999999999]\n",
      "[3.49, 514.53] 0.01669242864821374 True {}\n",
      "Reset now\n",
      "Reset, new obs :  [  3.2  428.35]\n",
      "[0.20000000000000018, 36.450000000000045]\n",
      "[3.2, 428.72] 0.13717421124828502 True {}\n",
      "Reset now\n",
      "Reset, new obs :  [  3.67 491.5 ]\n",
      "[3.67, 492.37] 0.0149104626716567 False {}\n",
      "[3.67, 494.18] 0.014645641383895944 False {}\n",
      "[3.67, 494.65] 0.01457840704661883 False {}\n",
      "[3.67, 496.59] 0.014307297866495743 False {}\n",
      "[3.55, 483.97] 0.019827500743531276 False {}\n",
      "[3.55, 483.97] 0.019827500743531276 False {}\n",
      "[0.43000000000000016, 78.08000000000004]\n",
      "[3.43, 470.35] 0.029784597788791434 True {}\n",
      "Reset now\n",
      "Reset, new obs :  [  3.91 520.04]\n",
      "[3.91, 520.04] 0.008600619072560843 False {}\n",
      "[3.91, 521.32] 0.008515312660992624 False {}\n",
      "[3.79, 507.06] 0.011027291443593747 False {}\n",
      "[3.79, 508.41] 0.010899111286465696 False {}\n",
      "[3.79, 509.34] 0.010812529126250333 False {}\n",
      "[3.67, 495.61] 0.01444297767982229 False {}\n",
      "[3.67, 495.61] 0.01444297767982229 False {}\n",
      "[3.55, 480.91] 0.020511978995733503 False {}\n",
      "[0.4900000000000002, 83.30000000000001]\n",
      "[3.49, 475.57] 0.024499595756670003 True {}\n",
      "Reset now\n",
      "Reset, new obs :  [  3.9  516.88]\n",
      "[3.84, 509.53] 0.010152449176839422 False {}\n",
      "[3.72, 496.38] 0.013340590614627687 False {}\n",
      "[3.67, 489.43] 0.015361643818781759 False {}\n",
      "[3.61, 482.48] 0.01817253366916175 False {}\n",
      "[0.4900000000000002, 77.19]\n",
      "[3.49, 469.46] 0.02643886936819033 True {}\n",
      "Reset now\n",
      "Reset, new obs :  [  2.73 375.26]\n",
      "[2.73, 375.26] 0.21773684325124665 False {}\n",
      "[2.73, 374.38] 0.20702647868662416 False {}\n",
      "[2.79, 381.72] 0.4513653802753349 False {}\n",
      "[2.79, 380.87] 0.4177109440267344 False {}\n",
      "[2.79, 379.22] 0.3648969166210559 False {}\n",
      "[2.91, 392.74] 23.640661938532944 False {}\n",
      "[2.91, 392.74] 23.640661938532944 False {}\n",
      "[0.029999999999999805, 14.410000000000025]\n",
      "[3.03, 406.68] 2.31320842007866 True {}\n",
      "Reset now\n",
      "Reset, new obs :  [  3.31 451.52]\n",
      "[0.31000000000000005, 61.25999999999999]\n",
      "[3.31, 453.53] 0.052657630617252746 True {}\n",
      "Reset now\n",
      "Reset, new obs :  [  3.43 466.71]\n",
      "[0.43000000000000016, 76.47000000000003]\n",
      "[3.43, 468.74] 0.03041168295212287 True {}\n",
      "Reset now\n",
      "Reset, new obs :  [  2.01 287.09]\n",
      "[2.01, 287.09] 0.009603546397613709 False {}\n",
      "[2.07, 292.71] 0.01080020909204802 False {}\n",
      "[2.19, 306.98] 0.014474943149660786 False {}\n",
      "[2.25, 313.5] 0.016926918031399438 False {}\n",
      "[2.37, 328.2] 0.024774490202927858 False {}\n",
      "[2.37, 326.62] 0.02417824200002419 False {}\n",
      "[2.49, 340.93] 0.03819213700283389 False {}\n",
      "[2.61, 354.88] 0.06857722824558878 False {}\n",
      "[2.61, 354.15] 0.06726397072671991 False {}\n",
      "[2.73, 367.78] 0.15123330762367096 False {}\n",
      "[2.84, 382.13] 0.6163708086785012 False {}\n",
      "[2.9, 389.47] 3.5714285714286262 False {}\n",
      "[0.020000000000000018, 11.900000000000034]\n",
      "[3.02, 404.17] 4.201680672268892 True {}\n",
      "Reset now\n",
      "Reset, new obs :  [  2.36 323.7 ]\n"
     ]
    }
   ],
   "source": [
    "env = PlaytimeEnv(first_c)\n",
    "\n",
    "num_steps = 150\n",
    "obs = env.reset()\n",
    "for step in range(num_steps):\n",
    "    # take random action, but you can also do something more intelligent\n",
    "    # action = my_intelligent_agent_fn(obs) \n",
    "    # action = policy(obs)\n",
    "    action = env.action_choose(obs)\n",
    "    # apply the action\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    print(obs, reward, done, info)\n",
    "    # Render the env\n",
    "    # env.render()\n",
    "\n",
    "    # Wait a bit before the next frame unless you want to see a crazy fast video\n",
    "    time.sleep(0.001)\n",
    "    \n",
    "    # If the episode is up, then start another one\n",
    "    if done:\n",
    "        print(\"Reset now\")\n",
    "        env.reset()\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try to add an agent with a deep learning neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = (len(env.observation_space.spaces.keys()),)\n",
    "actions = len(env.action_space.spaces.keys())  # sum(action.n for action in env.action_space.spaces.values())\n",
    "num_hidden = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,) 3\n"
     ]
    }
   ],
   "source": [
    "print(states, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Playtime-sketch\\Project - Sketch\\src\\ReinforcementLearning.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Playtime-sketch/Project%20-%20Sketch/src/ReinforcementLearning.ipynb#ch0000025?line=0'>1</a>\u001b[0m \u001b[39mdel\u001b[39;00m model\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrée : paramètres de wheel\n",
    "# Ajouter aussi les choix de plusieurs manoeuvres\n",
    "\n",
    "inputs = Input(shape=states)\n",
    "first = Dense(num_hidden, activation='relu')(inputs)\n",
    "second = Dense(num_hidden, activation='relu')(first)\n",
    "out_speed = Dense(env.action_space.spaces['speed'].n, activation='linear')(second)\n",
    "out_altitude = Dense(env.action_space.spaces['altitude'].n, activation='linear')(second)\n",
    "out_distance = Dense(env.action_space.spaces['distance'].n, activation='linear')(second)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=[out_speed, out_altitude, out_distance])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 24)           72          ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 24)           600         ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 10)           250         ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 50)           1250        ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 6)            150         ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,322\n",
      "Trainable params: 2,322\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.agents import DDPGAgent, DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy \n",
    "from rl.memory import SequentialMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_agent(model, actions):\n",
    "    policy = BoltzmannQPolicy()\n",
    "    memory = SequentialMemory(limit=50000, window_length=1)\n",
    "    dqn = DQNAgent(model=model, memory=memory, policy=policy, \n",
    "                   nb_actions=actions, nb_steps_warmup=10, target_model_update=1e-2)\n",
    "    return dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'output'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\Playtime-sketch\\Project - Sketch\\src\\ReinforcementLearning.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Playtime-sketch/Project%20-%20Sketch/src/ReinforcementLearning.ipynb#ch0000019?line=0'>1</a>\u001b[0m dqn \u001b[39m=\u001b[39m build_agent(states, actions)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Playtime-sketch/Project%20-%20Sketch/src/ReinforcementLearning.ipynb#ch0000019?line=1'>2</a>\u001b[0m dqn\u001b[39m.\u001b[39mcompile(Adam(lr\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m), metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mmae\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Playtime-sketch/Project%20-%20Sketch/src/ReinforcementLearning.ipynb#ch0000019?line=2'>3</a>\u001b[0m dqn\u001b[39m.\u001b[39mfit(env, nb_steps\u001b[39m=\u001b[39m\u001b[39m50000\u001b[39m, visualize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;32md:\\Playtime-sketch\\Project - Sketch\\src\\ReinforcementLearning.ipynb Cell 17'\u001b[0m in \u001b[0;36mbuild_agent\u001b[1;34m(model, actions)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Playtime-sketch/Project%20-%20Sketch/src/ReinforcementLearning.ipynb#ch0000017?line=1'>2</a>\u001b[0m policy \u001b[39m=\u001b[39m BoltzmannQPolicy()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Playtime-sketch/Project%20-%20Sketch/src/ReinforcementLearning.ipynb#ch0000017?line=2'>3</a>\u001b[0m memory \u001b[39m=\u001b[39m SequentialMemory(limit\u001b[39m=\u001b[39m\u001b[39m50000\u001b[39m, window_length\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Playtime-sketch/Project%20-%20Sketch/src/ReinforcementLearning.ipynb#ch0000017?line=3'>4</a>\u001b[0m dqn \u001b[39m=\u001b[39m DQNAgent(model\u001b[39m=\u001b[39;49mmodel, memory\u001b[39m=\u001b[39;49mmemory, policy\u001b[39m=\u001b[39;49mpolicy, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Playtime-sketch/Project%20-%20Sketch/src/ReinforcementLearning.ipynb#ch0000017?line=4'>5</a>\u001b[0m                nb_actions\u001b[39m=\u001b[39;49mactions, nb_steps_warmup\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, target_model_update\u001b[39m=\u001b[39;49m\u001b[39m1e-2\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Playtime-sketch/Project%20-%20Sketch/src/ReinforcementLearning.ipynb#ch0000017?line=5'>6</a>\u001b[0m \u001b[39mreturn\u001b[39;00m dqn\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\rl\\agents\\dqn.py:106\u001b[0m, in \u001b[0;36mDQNAgent.__init__\u001b[1;34m(self, model, policy, test_policy, enable_double_dqn, enable_dueling_network, dueling_type, *args, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    105\u001b[0m \u001b[39m# Validate (important) input.\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlist\u001b[39m(model\u001b[39m.\u001b[39;49moutput\u001b[39m.\u001b[39mshape) \u001b[39m!=\u001b[39m \u001b[39mlist\u001b[39m((\u001b[39mNone\u001b[39;00m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnb_actions)):\n\u001b[0;32m    107\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mModel output \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39moutput\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m has invalid shape. DQN expects a model that has one dimension for each action, in this case \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnb_actions\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    109\u001b[0m \u001b[39m# Parameters.\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'output'"
     ]
    }
   ],
   "source": [
    "dqn = build_agent(states, actions)\n",
    "dqn.compile(Adam(lr=1e-3), metrics=['mae'])\n",
    "dqn.fit(env, nb_steps=50000, visualize=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f544ce1a915a9875fad91c894e2c0bcad4b7a79945aa6027ef3ad27810072aa6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
